{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(jsonl):\n",
    "    with open(jsonl, 'r') as file:\n",
    "        return [json.loads(line) for line in list(file)]\n",
    "    \n",
    "def load_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation, train, test = load_jsonl('data/val.jsonl'), load_jsonl('data/train.jsonl'), load_jsonl('data/test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers, questions, texts = [], [], []\n",
    "for corpus in train + validation + test:\n",
    "    texts.append(corpus['passage']['text'])\n",
    "    for question in corpus['passage']['questions']:\n",
    "        questions.append(question['question'])\n",
    "        for answer in question['answers']:\n",
    "            answers.append(answer['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_need_translation(s):\n",
    "    return bool(re.search('[а-яА-Я]', s))\n",
    "\n",
    "# is_need_translation('Хеллоу!') => True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_texts(texts, threshold=5, separator=''):\n",
    "    result = []\n",
    "    temp = []\n",
    "    char_counter = 0\n",
    "    separator_lenght = len(separator)\n",
    "    for idx, text in enumerate(texts):\n",
    "        text_lenght = len(text) + separator_lenght\n",
    "        assert not len(text) > threshold, 'Текст больше маски! (\\'%s\\' > %d)' % (text, treshold)\n",
    "        if char_counter + len(text) > threshold:\n",
    "            result.append(temp.copy())\n",
    "            temp.clear()\n",
    "            char_counter = 0\n",
    "        char_counter += text_lenght\n",
    "        temp.append(text)\n",
    "    if temp:\n",
    "        result.append(temp)\n",
    "    return result\n",
    "\n",
    "# split_texts(['Котик', 'это', 'вам', 'не', 'собака!'], 7) => [['Котик'], ['это', 'вам'], ['не'], ['собака!']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary(text_groups, translator=None):\n",
    "    dictionary = {}\n",
    "    for group in tqdm(text_groups):\n",
    "        translatable, not_translatable = [], []\n",
    "        for text in group:\n",
    "            if is_need_translation(text):\n",
    "                translatable.append(text)\n",
    "            else:\n",
    "                not_translatable.append(text)\n",
    "        if not_translatable:\n",
    "            dictionary.update({text: text for text in not_translatable})\n",
    "        if translatable:\n",
    "            # on global limit exceeded\n",
    "            try:\n",
    "                dictionary.update(dict(zip(translatable, translator(translatable))))\n",
    "            except:\n",
    "                return dictionary\n",
    "    return dictionary\n",
    "\n",
    "# make_dictionary([['Кот', 'it\\'s'], ['собака!']]) => {\"it's\": \"it's\", 'Кот': 'Cat', 'собака!': 'the dog!'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary(dictionary, file):\n",
    "    with open(file + '.json', 'w') as f:\n",
    "        json.dump(dictionary, f, sort_keys=False, indent=4, ensure_ascii=False, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yandex Translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! `yc iam create-token` for getting new token if current expires!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc_folder_id = 'b1g5geju4iflfiqq0fgi'\n",
    "yc_key = 't1.9euelZrJnZTKmZfHm5uezJXPx57Lle3rnpWajcaNmMacnYmRjI2Li8uSms3l8_d9Q34A-u8vK01N_N3z9z1yewD67y8rTU38.NmvNYWKNh80iJOgdTNz8oxOeuFyBeTzIMyOjQs0qppnc_rTiXNbNPZPKdHHaGaC13kPM9f-jYVo9bLJaFA9PCA'\n",
    "yc_treshold = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yc_translate(texts):\n",
    "    response = requests.post('https://translate.api.cloud.yandex.net/translate/v2/translate', \n",
    "                        data = json.dumps({'folder_id': yc_folder_id, 'texts': texts, 'targetLanguageCode': 'en', \"sourceLanguageCode\": \"ru\"}),\n",
    "                       headers={'Content-Type': 'application/json', 'Authorization': 'Bearer ' + yc_key})\n",
    "    return list(map(lambda translation: translation['text'], json.loads(response.content)['translations']))\n",
    "\n",
    "# yc_translate(['Привет!']) => ['Hi!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [02:00<00:00,  4.31s/it]\n"
     ]
    }
   ],
   "source": [
    "translated_quesitons = make_dictionary(split_texts(questions, threshold=yc_treshold), translator=yc_translate)\n",
    "save_dictionary(translated_quesitons, 'data/yc_questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [07:37<00:00,  5.72s/it]\n"
     ]
    }
   ],
   "source": [
    "translated_answers = make_dictionary(split_texts(answers, threshold=yc_treshold), translator=yc_translate)\n",
    "save_dictionary(translated_answers, 'data/yc_answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [09:35<00:00,  4.17s/it]\n"
     ]
    }
   ],
   "source": [
    "translated_texts = make_dictionary(split_texts(texts, threshold=yc_treshold), translator=yc_translate)\n",
    "save_dictionary(translated_texts, 'data/yc_texts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.google_trans import google_translator as GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = GoogleTranslator(url_suffix=\"ru\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_threshold = 4000\n",
    "gl_separator = '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gl_translate(texts):\n",
    "    sentences = translator.translate('\\n'.join(texts), lang_tgt='en', lang_src='ru')  \n",
    "    translate_text = \"\"\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence[0]\n",
    "        translate_text += sentence\n",
    "    return translate_text.split('\\n')\n",
    "\n",
    "#gl_translate(['Привет!', 'Как дела?', 'У меня все хорошо!']) => ['Hello!', 'How are you?', \"I'm all good!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:34<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "translated_quesitons = make_dictionary(split_texts(questions, threshold=gl_threshold, separator=gl_separator), translator=gl_translate)\n",
    "save_dictionary(translated_quesitons, 'data/gl_questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [07:37<00:00,  5.72s/it]\n"
     ]
    }
   ],
   "source": [
    "translated_answers = make_dictionary(split_texts(answers, threshold=gl_threshold, separator=gl_separator), translator=gl_translate)\n",
    "save_dictionary(translated_answers, 'data/gl_answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [09:35<00:00,  4.17s/it]\n"
     ]
    }
   ],
   "source": [
    "translated_texts = make_dictionary(split_texts(texts, threshold=gl_threshold, separator=gl_separator), translator=gl_translate)\n",
    "save_dictionary(translated_texts, 'data/gl_texts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
